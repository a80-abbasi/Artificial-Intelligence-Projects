{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\t\t\n",
    "<p></p>\n",
    "<p></p>\n",
    "<font size=5>\n",
    "In the Name of God\n",
    "<font/>\n",
    "<p></p>\n",
    " <br/>\n",
    "    <br/>\n",
    "    <br/>\n",
    "<font color=#FF7500>\n",
    "Sharif University of Technology - Departmenet of Computer Engineering\n",
    "</font>\n",
    "<p></p>\n",
    "<font color=blue>\n",
    "Artifical Intelligence - Dr. Mohammad Hossein Rohban\n",
    "</font>\n",
    "<br/>\n",
    "<br/>\n",
    "Fall 2021\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr/>\n",
    "\t\t<div align=center>\n",
    "\t\t    <font color=red size=6>\n",
    "\t\t\t    <br />\n",
    "Practical Assignment 4 Naive Bayes\n",
    "            \t<br/>\n",
    "\t\t\t</font>\n",
    "    <br/>\n",
    "    <br/>\n",
    "<font size=4> \n",
    "                <br/><b>\n",
    "              Cheating is Strongly Prohibited\n",
    "                </b><br/><br/>\n",
    "                <font color=red>\n",
    "Please run all the cells.\n",
    "     </font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collectable": true,
    "execution": {
     "iopub.execute_input": "2021-10-01T16:01:36.762477Z",
     "iopub.status.busy": "2021-10-01T16:01:36.762155Z",
     "iopub.status.idle": "2021-10-01T16:01:36.764025Z",
     "shell.execute_reply": "2021-10-01T16:01:36.763754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set your student number\n",
    "student_number = 98105879\n",
    "Name = 'Ali'\n",
    "Last_Name = 'Abbasi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules\n",
    "- You **are** allowed to add or remove cells.\n",
    "- By running the cell below, you can see if your jupyter file is accepted or not. This cell will also **generate a python file which you'll have to upload to Quera** (as well as your jupyter file). The python file will later be validated and if the code in both files doesn't match, **your Practical Assignment won't be graded**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to save your jupyter file before running this script\n",
    "from Helper_codes.validator import *\n",
    "\n",
    "python_code = extract_python(\"./Q1.ipynb\")\n",
    "with open(f'python_code_Q1_{student_number}.py', 'w') as file:\n",
    "    file.write(python_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes (40 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Author: Kimia Noorbakhsh\n",
    "\t\t\t<br/>\n",
    "                <font color=red>\n",
    "Please run all the cells.\n",
    "     </font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are going to implement a Naive Bayes Classifier for the MNIST Dataset (Well, of course, **from scratch**!). The MNIST data set is a vast database of handwritten digits that is commonly used to form various image processing systems. \n",
    "\n",
    "Please note the following before you continue:\n",
    "- After implementing your Classifier, train your model on the **train** section of the MNIST dataset and validate your model by testing it on the test set.\n",
    "- Note that if you use any of the **test** images during training or for improving the accuracy, you will not earn any points for this assignment. \n",
    "- Do not forget to use **Laplace Smoothing** to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Bayes rule:\n",
    "    $$P(c|x) =  \\frac{P(x|c)P(c)}{P(x)} \\;\\;\\;\\;(1)$$\n",
    "    \n",
    "Here $x$ stands for the image, or more precisely, the pixel values of the formatted image as a vector, and $c$ stands for the number, which can be 0, 1, ..., 9. We can read the left side $P(c|x)$ as \"the probability of the class being $c$ given the $x$\" data (posterior). We can read the right side $P(x|c)$ as \"the probability of $x$ data being in the $c$\" class (likelihood). We care about the value of $c$. It tells us \"what number\" this picture is. The chosen class is simply the one with the highest probability for this data:\n",
    "$$c^* = argmax_{c}P(c|x)$$\n",
    "Now, we can ignore $P(x)$ in equation (1) (why?). Using this information, we can simplify our problem so that, in order to choose “which digit” given an image, all we need to do is calculate this argmax (P(x) is removed):\n",
    "$$c^* = argmax_{c}P(x|c)P(c)$$\n",
    "Now, we need to think about how to calculate $P(c)$, and $P(x|c)$. We leave this section for you to think about ^_^. But as a guide for $P(x|c)$, read the following. \n",
    "\n",
    "Remember that pixels represent the intensity of light, and that the intensity of light is in fact continuous. A first reasonable estimation to model continuous data is the multivariate Gaussian or multivariate Normal. We can write:\n",
    "$$P(x|c) = \\frac{1}{\\sqrt{(2\\pi)^{D}|\\Sigma|}}\\exp(-\\frac{1}{2}(x - \\mu)^{T}\\Sigma^{-1}(x-\\mu))$$\n",
    "Note that because probabilities are very small when dimensionality is high, we are going to work with log-probability rather than probability. So instead of getting numbers that are very close to 0, which is inaccurate when you use a computer to represent them, we're just going to get negative numbers. The log-probability can be represented as ($D$ is the dimentionality):\n",
    "$$\\log{P(x|c) = -\\frac{D}{2}\\ln(2\\pi)-\\frac{1}{2}\\ln|\\Sigma|-\\frac{1}{2}(x - \\mu)^{T}\\Sigma^{-1}(x-\\mu)}$$\n",
    "To calculate $\\mu$ and $\\Sigma$, you can use the **sample** mean and covariance (see [here.](https://en.wikipedia.org/wiki/Sample_mean_and_covariance)) Also note that to get the argmax over $P(x|c)P(c)$, we can choose the digit class using:\n",
    "$$c^* = argmax_{c}(\\log P(x|c)+\\log P(c))$$\n",
    "Now, let's dive into implementing a **Gaussian Naive Bayes Classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collectable": true
   },
   "source": [
    "For your convineince, use the following cells to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision\n",
    "# !pip install numpy\n",
    "# and other libraries you might need\n",
    "\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('./data', train=True, download=True)\n",
    "test_data  = datasets.MNIST('./data', train=False, download=True)\n",
    "\n",
    "train_images = np.array(train_data.data)\n",
    "train_labels = np.array(train_data.targets)\n",
    "test_images = np.array(test_data.data)\n",
    "test_labels = np.array(test_data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of data:\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayes:\n",
    "    def __init__(self, dim=784, number_of_classes=10):\n",
    "        self.k = number_of_classes\n",
    "        self.d = dim\n",
    "        self.pi = np.zeros(self.k)\n",
    "        self.mu = np.zeros((self.k, self.d))\n",
    "        self.sigma = np.zeros((self.k, self.d, self.d))\n",
    "\n",
    "    def train(self, train_images, train_labels, pi_smoothing = 10, sigma_smoothing = 10, alpha = 0.1):\n",
    "        data = train_images.reshape(-1, self.d)\n",
    "        n = len(data)\n",
    "        total_mean = data.mean(axis=0)\n",
    "        for k in range(self.k):\n",
    "            data_k = data[train_labels == k]\n",
    "            n_k = len(data_k)\n",
    "            # Linear Interpolation\n",
    "            self.mu[k] = (1 - alpha) * data_k.mean(axis=0) + alpha * total_mean\n",
    "            # Smoothing\n",
    "            self.sigma[k] = np.cov(data_k, rowvar=False) + np.eye(self.d) * sigma_smoothing\n",
    "            # Laplace Smoothing\n",
    "            self.pi[k] = (n_k + pi_smoothing) / (n + pi_smoothing * self.k)\n",
    "\n",
    "    def calc_accuracy(self, images, labels):\n",
    "        classified = labels == self.predict_labels(images)\n",
    "        return classified.sum() / len(classified)\n",
    "\n",
    "    def predict_labels(self, images):\n",
    "        data = images.reshape(-1, self.d)\n",
    "        likelihoods = np.array([multivariate_normal.logpdf(data, mean=self.mu[i], cov=self.sigma[i], allow_singular=True) for i in range(self.k)])\n",
    "        posteriors = likelihoods + np.log(self.pi).reshape((self.k, 1))\n",
    "        return np.argmax(posteriors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Bayes()\n",
    "network.train(train_images, train_labels, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data (%) : 87.67\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test data (%) : \" + str(network.calc_accuracy(test_images, test_labels) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using higher rates of smoothing would have resulted in higher accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data (%) : 94.36\n"
     ]
    }
   ],
   "source": [
    "smooth_net = Bayes()\n",
    "smooth_net.train(train_images, train_labels, 500, 500)\n",
    "print(\"Accuracy on test data (%) : \" + str(smooth_net.calc_accuracy(test_images, test_labels) * 100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f336af7d54ba0f0c1daaf2256eb85f31e983e88153daf7a27ef3ea6c724faba4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
